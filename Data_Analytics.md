# **【作成中】** 書籍やWebから得た知識を整理し、自分なりの知見などをまとめて行きます

### 参考書籍
武器としてのデータ分析力	中西達夫、畠慎一郎 著　日本実業出版社  
本物のデータ分析力が身につく本　河村真一ほか　日経BP  
ビッグデータ分析・活用のためのSQLレシピ　加嵜長門ほか　マイナビ

---

# データ分析の前提

## データ分析に必要なもの
1. データ  
   - トランザクションデータ「いつ・何を」
   - 属性データ「誰が」
   - 態度データ「なぜ」
   - 行動データ「どのように」
2. 理論  
   - 目的に対してどのような分析を行えばいいか
   - データをどう活用するか
3. ツール
   - ツールを選択し、操作する
   - データマネジメントし、分析する
4. ビジネス理解
5. 目的  
   分析をする際の大前提 ＝「ビジネスの目的」


## データ分析に必要な知識
1. 統計学
2. データマイニング
3. マーケティング
4. 業務知識とその関連知識


## データ分析にかかるコスト
分析ツールの導入にかかるコストは、分析の効果によってあげられる収益を上回らなければならない
- 導入
- 操作習得、習熟
- ランニングコスト（ライセンス料など）
- 効果を発揮するまでのリードタイム


## 分析を始める前に抑えたい３つの事項
### 1. データの基本形
   - データを一つの表形式にまとめる。データセット、テーブル。
### 2. データの呼び方
   - 変数 ... 表中の「列」
   - ケース ... 表中の「行」。事象（観測値、測定値、レコード）
   - サイズ、大きさ ... 表の行数（ケース数、レコード数）
### 3. データの種類（尺度水準）
   - 変数
     - 量的データ
       - 比率尺度 ... 差と比率が意味を持ち、原点０がある
       - 間隔尺度 ... 値の差が意味意味を持ち、原点０がない
     - 質的データ
       - 順序尺度 ... 値の大小関係のみに意味がある
       - 名義尺度 ... 区別するための記号

```
時系列データ ... 時間軸に沿って並べたデータ
横断面データ ... ある時点におけるデータ
パネルデータ ... 時系列データと横断面データを合わせたもの
```

---

# データの把握
## 基礎統計量
現状を正しく把握する
1. レコード件数
2. 平均値
3. 中央値
4. 最大値
5. 最小値
6. 分散、標準偏差


## 分布
**最もふさわしい確率分布を探し出して当てはめる**
### １変数の分布把握
 - ヒストグラム  
   平均値、中央値、分散、最頻値、尖度、歪度を可視化する
 - 確率分布  
   定型的な分布パターンに当てはめ、データから確率を予測する
   - 正規分布 ... 自然なばらつきの分布
   - 二項分布 ... 確率が一定の試行を繰り返したときの分布
   - ポアソン分布 ... 稀にしか起こらない事象の発生回数の分布

### １変数（時系列データ）の変化
 - トレンド  
   全体的な傾向
 - ボラティリティ  
   トレンドに対する個々の値のばらつき。分散、標準偏差


## 相関
**一方のデータが変動したとき、他方のデータがどの程度つられて動くか**
### ２変数の関係把握
 - 相関係数と散布図  
   ピアソンの相関係数 ... 量的データの関係性を示す     
   - 相関係数の注意点  
     1. 相関がない≠関係がない
     2. 外れ値の影響を大きく受ける
     3. いくつかのグループに分かれるデータの関係性は見えない
     4. 相関は因果関係ではない(擬似相関)  
        - どちらが原因で、どちらが結果なのかははっきりしない
        - 隠れた原因があるかもしれない
 - カイ二乗検定とクロス集計 ... 質的データの関係性を調べる

### ２変数の関係を見る指標
種類１ | 種類２ | 関係の指標  
--|---|---|
量的 | 量的 | ピアソンの相関係数
量的 | 質的 | 相関比</br>t検定などの検定</br>分散分布
質的</br>順序尺度 | 質的</br>順序尺度 | スピアマンの順位相関係数</br>ケンドールの順位相関係数
質的 | 質的 | クロス集計表</br>カイ二乗検定（独立性の検定）</br>クラメール係数

### ２変数の関係を見るグラフ
- 量的データ x 量的データ
  - 散布図
- 量的データ x 質的データ
  - 箱ひげ図
- 質的データ x 質的データ
  - クロス集計
  - 棒グラフ

---

# データ分析のタイプ（探索型と目的型）
## 探索型データ分析
探索型分析によって、ポジショニングマップを作成する
- 自社の現状を把握
- 市場で自らの置かれている立場を明確にする

→ 自社の強みと弱みを明らかにし、製品・サービスの改善ポイント、市場と顧客を見出す  
ポジショニングマップの作成を目標にすると良い

### 複数のデータから、背後にある因子をさぐりだす
- 因子分析 ... 量的データの探索  
- 数量化Ⅲ類、コレスポンデンス分析 ... 質的データの探索  

### 複数のデータを、共通する成分に要約する
- 主成分分析
- 多次元尺度構成法

### クラスタリング
コンピュータにより、データ間の距離、類似度を定義し、自動的にグループ分けを行う。  
手がかりの無い状態でも、分析を進めることができる。  
**因子分析によってマップの軸を設定し、クラスタリングによってグループを形作る。**

## 優良顧客を探し出す分析方法
**RFM分析とクラスタリングの組み合わせで真の優良顧客を見つける**

### RFM分析
R, F, Mの３つの指標で顧客を分類する
- "R"ecency (直近購入日)
- "F"requency (購入頻度)
- "M"onetary (累積購入金額)

### クラスタリング
下記の３つに注意しながら、グループ分け(セグメンテーション)する
- 各グループが独立(重複がない)であること
- そのグループでアプローチが可能なこと
- 商売にインパクトを与える十分なサイズがあること

## セグメンテーションの統計方法
セグメンテーションの二つの考え方
 - 外的基準によるグループ分け（セグメンテーション）  
   明示的な基準に基づいて行う。RFM分析など
 - クラスタリングによるグループ分け  
   コンピュータにより自動で行う。汎用性が高く、どんなデータでも試すことができる  
   - 階層型クラスタリング  
     距離の近いデータを集めてまとめる  
     グループを作成する過程を樹形図(デンドログラム)で視覚的に理解できる  
     - 最短距離法
     - 最長距離法
     - 群平均法　☆よく使う
     - ウォード法　☆よく使う
     - 重心法
   - 非階層型クラスタリング  
     計算量が少なく、大規模な処理に向いている
   　- k-means法  
   　  最初にグループ数を決めておく必要がある  
       結果が初期値に依存する

**クラスタリングに正解はない**
 1. うまくグルーピングできるとは限らない（結果の安定性を確認すべき）  
    - サンプリングした入力データをクラスタリングして同様の結果が得られるか確かめる
    - 何度かサンプリングとクラスタリングを繰り返し、同様のグループができるかを確かめる
 2. グループの解釈が難しいことがある  
    - グループ別の散布図を書いて比較する
    - 数が多い場合は、グループごとの分布の差異を数値化し、差異の大きい変数を重点的にチェックする
 3. どの手法がベストかわからない  
    - ウォード法か群平均法が良い（外れ値に強く、極端なクラスタができにくい）


## マップづくりの統計方法
探索型データ分析の目的は、データを一目で俯瞰できるマップを作ること  
**消費者志向の分析方法**
- 因子分析（対量的データ）  
  変数の相関に基づいて適切な軸を作る方法  
  **最も適切な向きに座標軸を再設定すること**＝因子分析の本質
  - 寄与率  
    各因子がどれだけの重みと情報量を持つかを示した数値
- コレスポンデンス分析（対質的データ）



# 目的型データ分析
目的変数を、複数の説明変数から導き出す  
→ 目的となる数字があり、その遷移に影響を与える要因を特定する  
説明変数から目的変数を予想する法則がアウトプットとなる

## 回帰分析
- ロジスティック回帰分析  
  目的変数が２値の場合
- 数量化Ⅰ類  
  説明変数が質的データ
- コンジョイント分析  
  マーケティングの分野で用いられ、製品・サービスを要素に分解し、結果に与える影響を調べる。  
  回帰分析は、コンジョイント分析で用いる手法のひとつ

## 消費者のニーズを見つけ出す分析方法
### コンジョイント分析
製品を構成する要因(属性)とそれぞれの要因の水準を設定して、複数の商品案をアンケートにより評価してもらい、  
**消費者の選好度を推定する調査・分析方法**  
- 線形回帰式  
  消費者の声を定量的に扱う
- 回帰係数（係数）  
  消費者の判断結果に対する要因を数値化したもの
  - 得点評価
  - 順位評価
  - 一対比較評価
- 直交表  
  全ての組み合わせの中から、結果を把握するのに効率の良い案を抽出する
- 重回帰分析  
  結果に最もよく当てはまる回帰式を探り当てる手法  
  結果に対する寄与度の大きい要因を選ばなければ、予測精度は下がる
  - 散布図と相関（量的データ）
  - クロス集計とカイ二乗値


## 機会損失を出さないための需要予測
過去の販売実績や出荷実績を元に予測を立てる
- 商品(製品在庫)の適正化
- 最適生産計画の立案

- 回帰分析によるトレンド予測  
  全体としての傾向に当てはまる直線を描き出す  
  - 線形回帰
    - 線形近似 ... 直線
    - 残差
    - 決定係数
  - 非線形回帰
    - 指数近似 ... 急速な成長の場合
    - 対数近似 ... 成長が徐々に鈍る場合
    - 多項式近似 ... 変動の回数が分かっている場合
    - 塁上近似 ... ベキ乗則に従う
  - ロジスティック回帰
- 確率分布によるボラティリティの評価  
  偶然による変動をデータの広がりの大きさとして把握する  
  - 正規分布
    1. 変動を分散として取り出す
    2. 正規分布に当てはめる
    3. 分布から確率を読み取る
  - ポワソン分布  
    売上が小さく、全く売上のない日があるような確率分布


---

# データ分析のプロセス
1. データ分析の設計
2. データの事前チェック
3. 分析方法の選択
4. 分析の実行
5. 分析結果の評価・解釈
6. 分析結果の表現

---

# データ分析組織
## チームメンバーの特性
- ビジネス、ITスキル、アナリティクスの全てを兼ね備えた人材は、離脱時のリスクが大きすぎる
- 疑い深い人間の方が、データを正しく扱える傾向がある
- 出てきた数値を元に推測して解釈し、コツコツと証拠を積み上げられる

## 外注する場合
- ビジネス理解を深めさせるた目のコミュニケーションが重要

## よくある落とし穴
1. 当たり前の結果しか得られない
   **データがあるから分析するのではなく、目的のためにデータ分析する**  
   成功している企業ほど、分析結果は周知の事実であることが多い  
   今正しいアクションを取っているかの確認と言う意味で、有意義である
2. データから見つけた新たな発見でもビジネスに生きなければ意味がない 　
   知的好奇心のままに分析を進めてはいけない   
   データ分析はビジネスや組織の目標達成のためのツールでしかない
3. 分析の目的を見失う  
   最初の目的や分析のプロセスはドキュメント化して、常に確認する  
   定期的にウォークスルーを実施する
4. データ分析にはコストがかかる  
   投資額に見合ったリターンが得られそうか十分に検討する  
   ビジネスモデルによっては、データ分析から受けられる恩恵が限定的であることも
5. 先入観や思い込みによる価値ある発見の見逃し  
   分析過程と結果はオープンにし、複数の人から意見を収集する
6. 有効なデータの存在に気づけない    
   システム部門と協業する
7. 分析プロセスや結果が消失する
   バックアップを必ず取る。複数名で作業する場合は、バージョン管理する
8. 一度きりの分析で終わってしまう
   分析は定常的に継続し改善し続けることで、効果を発揮する

---

# Webサービスで使えるデータ分析手法
```
writing
```

---

# データ分析に使うツール
### 解析言語
- Python
- R
- Julia

### 統計解析ソフト
- SAS
- SPSS

### BI
- 有料
  - Tableau
  - Power BI
- 無料
  - Google Data Studio
  - Redash

### アクセスログ解析
- Google Analytics
- Log Parser

---
**以下、未整理**


# 分析手法
## ■ クロス集計
## ■ 重回帰分析
## ■ ロジスティック回帰分析
## ■ ベイズ統計
## ■ ベイジアンネットワーク
## ■ コレスポンデンス分析
## ■ アソシエーション分析
## ■ 仮説検定
## ■ サポートベクターマシン
## ■ ランダムフォレスト
## ■ 協調フィルタリング


# フレームワーク
## ■ 3C分析
## ■ 4P分析
## ■ STP分析
## ■ whatツリー
## ■ whyツリー
## ■ カスタマージャーニー
## ■ AIDMA
## ■ AISAS
## ■ 5W2H
## ■ PEST
## ■ PLC
## ■ SWOT
## ■ MECE
## ■ アンゾフ成長マトリクス
## ■ VC
## ■ PPM
## ■ KBF,KSF
## ■ 7S
## ■ MCMC

---

## 売上の把握
1. 時系列に沿ってデータを集約
  - 日別の売上
  - 日別の推移（移動平均）
  - 当月売上の累計
  - 月別売上の昨対比
  - 業績推移（Zチャート）
2. 多面的な軸を使ってデータを集約
  - カテゴリ別の売上と小計
  - 売れ筋を判別（ABC分析）
  - 売れ行きの伸び率（ファンチャート）
  - 購入価格帯を集計（ヒストグラム）

## ユーザーの把握
1. ユーザー全体の特徴・傾向
  - ユーザのアクション数
  - 年齢別区分
  - 年齢別区分ごとの特徴
  - ユーザーの訪問頻度
  - ユーザのアクション数（ベン図で）
  - デシル分析
  - RFM分析
2. ユーザー全体の時系列による状態変化
  - 登録数の推移と傾向 ☆
  - 継続率と定着率 ☆
  - 継続と定着に影響するアクション ☆
  - アクション回数に応じた定着率 ☆
  - 利用日数に応じた定着率 ☆
  - ユーザーの残存率 ☆
  - 訪問頻度からユーザーの属性を定義 ☆
  - 訪問種別を定義して成長指数 ☆
3. 時系列に沿ったユーザーの個別のアクション
  - ユーザーのアクション間隔
  - カート追加後に購入されているか
  - 登録から経過日数別の売上


## Webサイト上の行動把握
1. サイト全体の特徴・傾向
  - 日次の訪問者数・訪問回数・ページビュー ☆
  - ページごとの訪問者数・訪問回数・ページビュー ☆
  - 流入元別の訪問回数・CVR ☆
  - アクセスされる曜日、時間帯 ☆
2. サイト内のユーザー行動
  - 入口ページと出口ページ ☆
  - 離脱率と直帰率 ☆
  - 成果に結びつくページ ☆
  - ページの価値 ☆
  - 検索条件ごとのユーザー行動 ☆
  - ユーザーの回遊可視化（フォールアウトレポート） ☆
  - サイト内のユーザーフロー ☆
  - ページの読了率 ☆
  - ユーザー行動の全体像 ☆
3. エントリーフォームの最適化
  - エラー率 ☆
  - 入力〜確認〜完了までの遷移率 ☆
  - フォーム直帰率 ☆
  - エラーが発生している項目と内容 ☆


## データ活用の精度を高める
1. データ加工で新たな切り口を作る
  - IPアドレスから国・地域を補完
  - 都道府県に隣接都道府県情報を付与
  - 土日・祝日を判定
  - １日の集計範囲を変更
2. 異常値の検出
  - データの分布 ☆
  - クローラーの除外 ☆
  - データの妥当性確認 ☆
  - 特定IPアドレスからのアクセス除外 ☆
3. データの重複を検出
  - マスタデータの重複検出
  - ログの重複検出
4. 複数のデータセット比較
  - データの差分抽出
  - ２つのランキング類似度


## データを武器にする
1. 検索機能を評価
  - NoMatch率とそのワード
  - 再検索率とそのワード
  - 再検索ワードを分類
  - 検索離脱率とそのワード
  - 検索ワードに関する指標の集計効率化
  - 検索結果の網羅性を指標化
  - 検索結果の妥当性を指標化
  - 検索結果の順位を考慮した指標
2. レコメンド
  - 広義なレコメンドシステム ☆
  - このアイテムに興味がある人はこんなアイテムも ☆
  - オススメの商品 ☆
  - レコメンドシステムの改善ポイント ☆
  - 表示時のポイント ☆
  - レコメンドに関する指標 ☆
3. スコアの計算
  - 複数の値をバランスよく組み合わせる ☆  
  - 値の範囲が異なる指標を正規化して比較可能にする ☆
  - 偏差値を計算する ☆
  - 巨大な数値の指標をわかりやすくする ☆
  - 独自のスコアリング方法を定義してランキングを作成する ☆


## データ活用
  - データの活用方法 ☆
  - データに関わる関係者
  - ログフォーマットを考える ☆
  - データを活用したい状態に整える ☆
  - データ分析のプロセス
  - 分析のはじめの一歩
  - 相手に応じたレポーティング ☆
  - さらなるデータ活用スキル
